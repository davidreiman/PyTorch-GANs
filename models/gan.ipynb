{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "latent_size = 100\n",
    "image_size = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.output = nn.Linear(512, output_size)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.output = nn.Linear(512, 1)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(shape):\n",
    "    z = torch.from_numpy(np.random.normal(size=shape)).float()\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        z = z.cuda()\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(),  download=True)\n",
    "\n",
    "# Data loader\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Labels\n",
    "one = torch.from_numpy(np.ones(shape=[batch_size, 1])).float()\n",
    "zero = torch.from_numpy(np.zeros(shape=[batch_size, 1])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "generator = Generator(latent_size, image_size)\n",
    "discriminator = Discriminator(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    loss = loss.cuda()\n",
    "    one = one.cuda()\n",
    "    zero = zero.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    for i, (image_real, label) in tqdm(enumerate(loader), desc=\"Example\", total=int(len(dataset)/batch_size)):\n",
    "        \n",
    "        image_real = image_real.view(-1, image_size)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image_real = image_real.cuda()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Discriminator sees true image\n",
    "        prob_real = discriminator(image_real)\n",
    "        loss_real = loss(prob_real, one)\n",
    "        \n",
    "        # Generator makes an image\n",
    "        z = get_latent([batch_size, latent_size])\n",
    "            \n",
    "        image_fake = generator(z)\n",
    "        \n",
    "        # Discriminator sees generated image\n",
    "        prob_fake = discriminator(image_fake)\n",
    "        loss_fake = loss(prob_fake, zero)\n",
    "        \n",
    "        loss_d = 0.5*(loss_real + loss_fake)\n",
    "        loss_d.backward()\n",
    "        \n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        \n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        # Generator makes another image\n",
    "        z = get_latent([batch_size, latent_size])\n",
    "\n",
    "        image_fake = generator(z)\n",
    "        \n",
    "        # Discriminator determines the probability it is a true image\n",
    "        prob_true = discriminator(image_fake)\n",
    "        loss_g = loss(prob_true, one)\n",
    "        loss_g.backward()\n",
    "        \n",
    "        optimizer_g.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
